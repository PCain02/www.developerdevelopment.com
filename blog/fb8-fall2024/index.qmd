---
author: [Pallas-Athena Cain, Coltin Colucci, Chezka Quinola, Gregory M. Kapfhammer]
title: Parsing Inputs
date: '2024-11-20'
date-format: long
categories: [post, software engineering, fuzzing book]
description: <em>How can input parsers help with fuzzing? How can parsing inputs make more inputs for fuzzing? </em>
toc: true
page-layout: full
---

## Overview

## Summary

Reminder a non-terminal is the rule or building blocks for the grammar such as `<digit>` and `<letter>` whereas a terminal is the actual digit or letter think of it as the desintation for the grammar like `2` or `a`.

Given a string you can decompose it into its constituent parts that correspond to the parts of grammar used to generate it. 

You can make a derivation tree of a given string to break it down into its grammar parts. Then it can be recombined using the same grammar to produce new strings. Trees allow us to mutatee, crossover, and recombine their parts in order to generate new valid slightly different inputs.

There are 2 main parsing classes we will look at today to make a string into a derivation tree.
- Parsing Expression Grammar Parser (PEGParser) 
- Earley Parsers

The PEGParser is efficient but limited to a specific grammar structure - rather than choosing all the rules that can potentially match it stops at the first match that succeeds.

The Earley Parser can accept any kind of context-free grammars and explore all parsing alternatives.

### To Use

To use these parsers first you have initiate a grammar.

```python
>>> from Grammars import US_PHONE_GRAMMAR
>>> us_phone_parser = EarleyParser(US_PHONE_GRAMMAR)
```

Then you use the parse method to retrieve a list of possible derivation trees:

```python
>>> trees = us_phone_parser.parse("(555)987-6543")
>>> tree = list(trees)[0]
>>> display_tree(tree)
```

![](example-tree.png)

These trees can be used for test generation. Notably for mutating and recombing existing inputs.

### Why Parsing for Fuzzing?

Sometimes trying to generate valid inputs for fuzzing can be hard. For example if you have code that can only run if the first item has to be the stings `van` or `car` to work but you are randomly generating the input the chances of getting those to output are very low.

We can give the input generator our grammar but just the grammar itself is not enough to make valid inputs. Even if you modify the fuzzer to know more about the way the inputs are formated there is still difficulty getting valid inputs.

```python
class PooledGrammarFuzzer(GrammarFuzzer):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._node_cache = {}

    def update_cache(self, key, values):
        self._node_cache[key] = values

    def expand_node_randomly(self, node):
        (symbol, children) = node
        assert children is None
        if symbol in self._node_cache:
            if random.randint(0, 1) == 1:
                return super().expand_node_randomly(node)
            return copy.deepcopy(random.choice(self._node_cache[symbol]))
        return super().expand_node_randomly(node)

gf = PooledGrammarFuzzer(CSV_GRAMMAR, min_nonterminals=4)
gf.update_cache('<item>', [
    ('<item>', [('car', [])]),
    ('<item>', [('van', [])]),
])
trials = 10
time = 0
for i in range(trials):
    vehicle_info = gf.fuzz()
    try:
        print(repr(vehicle_info), end="")
        process_vehicle(vehicle_info)
    except Exception as e:
        print("\t", e)
    else:
        print()
```

```
',h,van,|'	 Invalid entry
'M,w:K,car,car,van'	 Invalid entry
'J,?Y,van,van,car,J,~D+'	 Invalid entry
'S4,car,car,o'	 invalid literal for int() with base 10: 'S4'
'2*-,van'	 not enough values to unpack (expected at least 4, got 2)
'van,%,5,]'	 Invalid entry
'van,G3{y,j,h:'	 Invalid entry
'$0;o,M,car,car'	 Invalid entry
'2d,f,e'	 not enough values to unpack (expected at least 4, got 3)
'/~NE,car,car'	 not enough values to unpack (expected at least 4, got 3)
```

**The solution: A parser. A parser can extract the template for inputs and and valid values from samples and use them for fuzzing!**

### Using a Parser

The parser processes structured input. The parsers in this chapter take an input string and turn it into a derviation tree. 

The next chapter is about using the parser for testing but this chapter is about understanding how parsers work. 

### An Ad Hoc Parser

```python
# Used to extract the information
def simple_parse_csv(mystring: str) -> DerivationTree:
    children: List[DerivationTree] = []
    tree = (START_SYMBOL, children)
    for i, line in enumerate(mystring.split('\n')):
        children.append(("record %d" % i, [(cell, [])
                                           for cell in line.split(',')]))
    return tree

# Change the orientation to Left to Right
def lr_graph(dot):
    dot.attr('node', shape='plain')
    dot.graph_attr['rankdir'] = 'LR'

tree = simple_parse_csv(mystring)
display_tree(tree, graph_attr=lr_graph)
```
![](csv-lr-graph.png)

This is a simple example and if we encounter more complexity it may not parse correctly. We can separate these incorrectly parsed inputs manually but that would be insanity! It would be so much work. Instead we use formal parsers. With those changing the external structure does not have much impact on the internal structure.

### Grammars in Parsing

Non-terminals are the building block rules that may be expanded. The symbols themselves are typically terminals unless they can be expanded further.

Here is an example derivation tree for this grammar:

```python
tree = ('<start>', [('<expr>',
                     [('<expr>', [('<integer>', [('<digit>', [('1', [])])])]),
                      ('+', []),
                      ('<expr>', [('<integer>', [('<digit>', [('2',
                                                               [])])])])])])
assert mystring == tree_to_string(tree)
display_tree(tree)
```

![](derivation-tree.png)

#### Recursion

Recursion is possible in grammar such as with `<expr>` being used in its own definition. There are two kinds of recurision to note in parsing left-recursive and right-recursive.

**Left-recursive**

A nonterminal is directly left-recursive if the left-most symbol of any of its productions is itself.

Example:

```python
LR_GRAMMAR: Grammar = {
    '<start>': ['<A>'],
    '<A>': ['<A>a', ''],
}

mystring = 'aaaaaa'
display_tree(
    ('<start>', [('<A>', [('<A>', [('<A>', []), ('a', [])]), ('a', [])]),
                 ('a', [])]))
```

![](left-tree.png)

A grammar can also be indirectly left-recursive if the left-most symbols can be expanded using their definitions to produce the nonterminal as the left-most symbol of the expansion. For example `<integer>` will be considered hidden-left recursive if `<digit>` could derive an empty string.

**Right-recurisve**

Right recursive is the same idea but it expands the other direction.

```python
RR_GRAMMAR: Grammar = {
    '<start>': ['<A>'],
    '<A>': ['a<A>', ''],
}

display_tree(('<start>', [('<A>', [
                  ('a', []), ('<A>', [('a', []), ('<A>', [('a', []), ('<A>', [])])])])]
             ))
```

![](right-tree.png)

#### Abiguity

Sometimes there are multiple trees from the same grammar called **parses**. The sting `1+2+3` has two ways it can be parsed using the `A1_GRAMMAR`. One method to deal with this is to simply choose an order of resolution, perhaps choose the first tree in any case (PEGParser). Another approach returns all the trees (Earley parser).

### A Parser Class

To develop parsers there needs to be defined interface for parsing. There are two approaches to parsing a string using a grammar.

The first approach is to use a lexer.  A lexer tokenizes an incoming string then feeds the grammar one token at a time. Each token represents a meaningful unit such as a number or keyword. The lexer handles the tokenization process, while the parser only has to focus on understanding the structure of the language using these tokens. The result of parsing is usually a shallow derivation tree, which can be converted into an Abstract Syntax Tree (AST).

The second approach is using a tree pruner. This occurs after the complete parse. The tree pruner removes the nodes that correspond to individual tokens and then replaces them with their actual string values as leaf nodes. This approach is more flexible and powerful additionally there is no separate step for lexing and parsing.

### Parsing Expression Grammars

Parsing Expression Grammars (PEG) are recognition based grammars that specify a sequence of steps to take to parse a given string. Parsing expression grammars are represented by a set of nonterminals and corresponding alternatives representing how to match each. 

```python
PEG1 = {
    '<start>': ['a', 'b']
}
```

Unlike context-free grammars alternatives represent ordered choices, meaning the parser will stop at the first matching rule it finds. 

```python
PEG2 = {
    '<start>': ['ab', 'abc']
}
```

### The Packrat Parser for Predicate Expression Grammars

### Parsing COntext-Free Grammars

#### Problems with PEG

### The Earley Parser

### Excursion: Testing the Parsers

### Background

## Reflection

## Action Items


<!-- Include the license statement for the online book -->
{{< include /_fuzzingbook-reference.qmd >}}

<!-- Include reference back to the listing of blog posts -->
{{< include /_back-blog.qmd >}}